{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = './origin_data/test_untagged.txt'\n",
    "full_data = pd.read_csv(dataPath, header=None, sep='\\t').iloc[:, 2:]\n",
    "full_data.columns = ['e1', 'e2', 'rel', 'sen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add entity tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_entity_tag(row):\n",
    "    token_sen = row['sen'].split()\n",
    "    out_token_sen = copy.deepcopy(token_sen)\n",
    "    update_list_e1 = []\n",
    "    update_list_e2 = []\n",
    "    for i, j in enumerate(token_sen):\n",
    "        if j == row['e1']:\n",
    "            tmp = i+len(update_list_e1)+len(update_list_e2)\n",
    "            out_token_sen.insert(tmp, '[E1]')\n",
    "            out_token_sen.insert(tmp+2, '[/E1]')\n",
    "            \n",
    "            update_list_e1.append(tmp)\n",
    "            update_list_e1.append(tmp+2)\n",
    "        if j == row['e2']:\n",
    "            tmp = i+len(update_list_e1)+len(update_list_e2)\n",
    "            update_list_e2.append(tmp)\n",
    "            update_list_e2.append(tmp+2)\n",
    "            out_token_sen.insert(tmp, '[E2]')\n",
    "            out_token_sen.insert(tmp+2, '[/E2]')\n",
    "    temp_row = copy.deepcopy(row)\n",
    "    temp_row['sen'] = ' '.join(out_token_sen)\n",
    "    return ' '.join(out_token_sen), temp_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('the occasion was suitably exceptional : a reunion of the 1970s-era sam rivers trio , with [E1] dave_holland [/E1] on bass and [E2] barry_altschul [/E2] on drums .', e1                                          dave_holland\ne2                                        barry_altschul\nrel                                                  NaN\nsen    the occasion was suitably exceptional : a reun...\nName: 0, dtype: object)\n"
    }
   ],
   "source": [
    "# Function verification\n",
    "print(_add_entity_tag(full_data.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_bert_data(dataPath):\n",
    "    full_data = pd.read_csv(dataPath, header=None, sep='\\t').iloc[:, 2:]\n",
    "    full_data.columns = ['e1', 'e2', 'rel', 'sen']\n",
    "    tagged_sen = []\n",
    "    row_list = []\n",
    "    with tqdm(total=len(full_data)) as pbar:\n",
    "        for _, row in full_data.iterrows():\n",
    "            temp_sen, temp_row = _add_entity_tag(row)\n",
    "            tagged_sen.append(temp_sen)\n",
    "            if len(temp_row['sen'].split())<512:\n",
    "                row_list.append(temp_row)\n",
    "            pbar.update(1)\n",
    "    full_data.drop(columns='sen')\n",
    "    full_data['seq'] = tagged_sen\n",
    "    full_data = full_data.fillna(value='UNK')\n",
    "    \n",
    "    cleaned_df = pd.DataFrame(row_list)\n",
    "    cleaned_df = cleaned_df.fillna(value='UNK')\n",
    "    cleaned_df = cleaned_df.iloc[:, 2:]\n",
    "    cleaned_df.to_csv(dataPath[:-4]+'_filtered.txt', index=False, sep='\\t')\n",
    "    full_data.to_csv(dataPath[:-4]+'_bert.txt', index=False, sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_text(dataPath):\n",
    "    output = []\n",
    "    with open(dataPath, 'r') as origin_file:\n",
    "        baselen = 0\n",
    "        n_line = 1\n",
    "\n",
    "        for line in origin_file.readlines():\n",
    "            line = line.strip()\n",
    "            token = line.split('\\t')\n",
    "            if baselen == 0:\n",
    "                baselen = len(token)\n",
    "            else:\n",
    "                if len(token) != baselen:\n",
    "                    print(token)\n",
    "                    print(n_line)\n",
    "            n_line += 1\n",
    "            temp = '\\t'.join(token[:6])+'\\n'\n",
    "            output.append(temp)\n",
    "    os.rename(dataPath, dataPath[:-4]+'_original.txt')\n",
    "    with open(dataPath, 'w') as outfile:\n",
    "        outfile.writelines(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 172448/172448 [02:30<00:00, 1144.63it/s]\n"
    }
   ],
   "source": [
    "prepare_bert_data('./origin_data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70730/70730 [00:48<00:00, 1449.71it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tagged_sen = []\n",
    "with tqdm(total=len(full_data)) as pbar:\n",
    "    for _, row in full_data.iterrows():\n",
    "        tagged_sen.append(_add_entity_tag(row))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sen. charles e. schumer called on federal safety officials yesterday to reopen their investigation into the fatal crash of a passenger jet in [E2] belle_harbor [/E2] , [E1] queens [/E1] , because equipment failure , not pilot error , might have been the cause .\n"
     ]
    }
   ],
   "source": [
    "print(full_data.iloc[0]['tagged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_filter(dataPath):\n",
    "    df = pd.read_csv(dataPath, sep='\\t', header=None)\n",
    "    df.columns=['labels', 'text']\n",
    "#    df.to_json(dataPath[:-3]+'json', orient='records')\n",
    "    df.to_json(dataPath[:-3]+'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_filter('./origin_data/train_filtered.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_long(path):\n",
    "    df = pd.read_csv(path, header=None, sep='\\t')\n",
    "    temp = []\n",
    "    for _, row in df.iterrows():\n",
    "        token = row.iloc[-1].split()\n",
    "        if len(token)<480:\n",
    "            temp.append(row)\n",
    "        else:\n",
    "            print(len(token))\n",
    "    print(len(temp))\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "172448\n172448\n"
    }
   ],
   "source": [
    "filter_long('./origin_data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "def convert_label(path):\n",
    "    \n",
    "    df = pd.read_csv(path, header=None, sep='\\t')\n",
    "    if not hasattr(le, 'classes_'):\n",
    "        le.fit(df.iloc[:, 0])\n",
    "    df.iloc[:, 0] = le.transform(df.iloc[:, 0])\n",
    "    \n",
    "    df.to_csv(path, header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_label('./origin_data/train_filtered.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False\n"
    }
   ],
   "source": [
    "print(hasattr(le, 'classes_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_label('./origin_data/test_filtered.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitac168c6609954e00ab6461e74f5908a0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}