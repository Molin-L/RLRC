{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordembedding = np.load('./origin_data/vec.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word = np.load('./data/testall_word.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add entity tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_entity_tag(row):\n",
    "    token_sen = row['sen'].split()\n",
    "    out_token_sen = copy.deepcopy(token_sen)\n",
    "    update_list_e1 = []\n",
    "    update_list_e2 = []\n",
    "    for i, j in enumerate(token_sen):\n",
    "        if j == row['e1']:\n",
    "            tmp = i+len(update_list_e1)+len(update_list_e2)\n",
    "            out_token_sen.insert(tmp, '[E1]')\n",
    "            out_token_sen.insert(tmp+2, '[/E1]')\n",
    "            \n",
    "            update_list_e1.append(tmp)\n",
    "            update_list_e1.append(tmp+2)\n",
    "        if j == row['e2']:\n",
    "            tmp = i+len(update_list_e1)+len(update_list_e2)\n",
    "            update_list_e2.append(tmp)\n",
    "            update_list_e2.append(tmp+2)\n",
    "            out_token_sen.insert(tmp, '[E2]')\n",
    "            out_token_sen.insert(tmp+2, '[/E2]')\n",
    "    temp_row = copy.deepcopy(row)\n",
    "    temp_row['sen'] = ' '.join(out_token_sen)\n",
    "    return ' '.join(out_token_sen), temp_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the occasion was suitably exceptional : a reunion of the 1970s-era sam rivers trio , with [E1] dave_holland [/E1] on bass and [E2] barry_altschul [/E2] on drums .', e1                                          dave_holland\n",
      "e2                                        barry_altschul\n",
      "rel                                                  NaN\n",
      "sen    the occasion was suitably exceptional : a reun...\n",
      "Name: 0, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Function verification\n",
    "print(_add_entity_tag(full_data.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_bert_data(dataPath):\n",
    "    full_data = pd.read_csv(dataPath, header=None, sep='\\t').iloc[:, 2:]\n",
    "    full_data.columns = ['e1', 'e2', 'rel', 'sen']\n",
    "    tagged_sen = []\n",
    "    row_list = []\n",
    "    with tqdm(total=len(full_data)) as pbar:\n",
    "        for _, row in full_data.iterrows():\n",
    "            temp_sen, temp_row = _add_entity_tag(row)\n",
    "            tagged_sen.append(temp_sen)\n",
    "            if len(temp_row['sen'].split())<512:\n",
    "                row_list.append(temp_row)\n",
    "            pbar.update(1)\n",
    "    full_data.drop(columns='sen')\n",
    "    full_data['seq'] = tagged_sen\n",
    "    full_data = full_data.fillna(value='UNK')\n",
    "    \n",
    "    cleaned_df = pd.DataFrame(row_list)\n",
    "    cleaned_df = cleaned_df.fillna(value='UNK')\n",
    "    cleaned_df = cleaned_df.iloc[:, 2:]\n",
    "    cleaned_df.to_csv(dataPath[:-4]+'_filtered.txt', index=False, sep='\\t')\n",
    "    full_data.to_csv(dataPath[:-4]+'_bert.txt', index=False, sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_text(dataPath):\n",
    "    output = []\n",
    "    with open(dataPath, 'r') as origin_file:\n",
    "        baselen = 0\n",
    "        n_line = 1\n",
    "\n",
    "        for line in origin_file.readlines():\n",
    "            line = line.strip()\n",
    "            token = line.split('\\t')\n",
    "            if baselen == 0:\n",
    "                baselen = len(token)\n",
    "            else:\n",
    "                if len(token) != baselen:\n",
    "                    print(token)\n",
    "                    print(n_line)\n",
    "            n_line += 1\n",
    "            temp = '\\t'.join(token[:6])+'\\n'\n",
    "            output.append(temp)\n",
    "    os.rename(dataPath, dataPath[:-4]+'_original.txt')\n",
    "    with open(dataPath, 'w') as outfile:\n",
    "        outfile.writelines(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172448/172448 [02:30<00:00, 1144.63it/s]\n"
     ]
    }
   ],
   "source": [
    "prepare_bert_data('./origin_data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70730/70730 [00:48<00:00, 1449.71it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tagged_sen = []\n",
    "with tqdm(total=len(full_data)) as pbar:\n",
    "    for _, row in full_data.iterrows():\n",
    "        tagged_sen.append(_add_entity_tag(row))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sen. charles e. schumer called on federal safety officials yesterday to reopen their investigation into the fatal crash of a passenger jet in [E2] belle_harbor [/E2] , [E1] queens [/E1] , because equipment failure , not pilot error , might have been the cause .\n"
     ]
    }
   ],
   "source": [
    "print(full_data.iloc[0]['tagged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_filter(dataPath):\n",
    "    df = pd.read_csv(dataPath, sep='\\t', header=None)\n",
    "    df.columns=['labels', 'text']\n",
    "#    df.to_json(dataPath[:-3]+'json', orient='records')\n",
    "    df.to_json(dataPath[:-3]+'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_filter('./origin_data/train_filtered.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_long(path):\n",
    "    df = pd.read_csv(path, header=None, sep='\\t')\n",
    "    temp = []\n",
    "    for _, row in df.iterrows():\n",
    "        token = row.iloc[-1].split()\n",
    "        if len(token)<480:\n",
    "            temp.append(row)\n",
    "        else:\n",
    "            print(len(token))\n",
    "    print(len(temp))\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172448\n",
      "172448\n"
     ]
    }
   ],
   "source": [
    "filter_long('./origin_data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "def convert_label(path):\n",
    "    \n",
    "    df = pd.read_csv(path, header=None, sep='\\t')\n",
    "    if not hasattr(le, 'classes_'):\n",
    "        le.fit(df.iloc[:, 0])\n",
    "    df.iloc[:, 0] = le.transform(df.iloc[:, 0])\n",
    "    \n",
    "    df.to_csv(path, header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_label('./origin_data/train_filtered.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(hasattr(le, 'classes_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_label('./origin_data/test_filtered.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word emebedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "pretrain_model = \"bert-base-uncased\"\n",
    "additional_special_tokens = ['[E1]', '[/E1]', '[E2]', '[/E2]']\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrain_model, do_lower_case=True, additional_special_tokens = additional_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenization(tokenizer, row):\n",
    "    '''\n",
    "    Tokenize the sentences from filter data\n",
    "    '''\n",
    "    sentence = '[CLS] '+row.iloc[-1]+' [SEP]'\n",
    "    token = tokenizer.tokenize(sentence)\n",
    "    return len(token)\n",
    "\n",
    "def bert_token_filter(path):\n",
    "    original_data = pd.read_csv(path, sep='\\t', header=None)\n",
    "    temp_row = []\n",
    "    for _, row in tqdm(original_data.iterrows()):\n",
    "        token_len = tokenization(tokenizer, row)\n",
    "        if token_len>512:\n",
    "            print(token_len)\n",
    "        else:\n",
    "            row.iloc[-1] = '[CLS] '+row.iloc[-1]+' [SEP]'\n",
    "            temp_row.append(row)\n",
    "    out_df = pd.DataFrame(temp_row)\n",
    "    out_df.to_csv(path[:-4]+'_bf.txt', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38079it [00:25, 1446.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39392it [00:26, 1420.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41419it [00:27, 1454.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46061it [00:31, 1414.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816\n",
      "712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50107it [00:34, 1404.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56215it [00:38, 1421.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713\n",
      "785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67086it [00:46, 1429.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70729it [00:48, 1448.60it/s]\n",
      "172448it [02:05, 1375.69it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = [\n",
    "    './origin_data/train_filtered.txt',\n",
    "    './origin_data/test_filtered.txt'\n",
    "]\n",
    "for i in data_path:\n",
    "    bert_token_filter(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>sen. charles e. schumer called on federal safe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>but instead there was a funeral , at st. franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>rosemary antonelle , the daughter of teresa l....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>one was for st. francis de sales roman catholi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>the firefighter , whom a fire department offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70724</th>\n",
       "      <td>53</td>\n",
       "      <td>it gets pretty loud , '' the [E1] williams [/E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70725</th>\n",
       "      <td>53</td>\n",
       "      <td>cherished grandmother of [E1] natalie [/E1] , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70726</th>\n",
       "      <td>53</td>\n",
       "      <td>cherished grandmother of [E1] natalie [/E1] , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70727</th>\n",
       "      <td>53</td>\n",
       "      <td>among those present at the ceremony were phil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70728</th>\n",
       "      <td>53</td>\n",
       "      <td>in a statement , the [E1] vatican [/E1] said i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70729 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                                  1\n",
       "0      29  sen. charles e. schumer called on federal safe...\n",
       "1      29  but instead there was a funeral , at st. franc...\n",
       "2      29  rosemary antonelle , the daughter of teresa l....\n",
       "3      29  one was for st. francis de sales roman catholi...\n",
       "4      29  the firefighter , whom a fire department offic...\n",
       "...    ..                                                ...\n",
       "70724  53  it gets pretty loud , '' the [E1] williams [/E...\n",
       "70725  53  cherished grandmother of [E1] natalie [/E1] , ...\n",
       "70726  53  cherished grandmother of [E1] natalie [/E1] , ...\n",
       "70727  53  among those present at the ceremony were phil ...\n",
       "70728  53  in a statement , the [E1] vatican [/E1] said i...\n",
       "\n",
       "[70729 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitac168c6609954e00ab6461e74f5908a0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}